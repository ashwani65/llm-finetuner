# LLM Fine-tuner: Production-Ready LoRA Fine-tuning Pipeline

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.1+-ee4c2c.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**Production-grade pipeline for fine-tuning Large Language Models using LoRA/QLoRA with automated deployment, evaluation, and experiment tracking.**

<div align="center">
  <img src="https://img.shields.io/badge/HuggingFace-Transformers-orange" />
  <img src="https://img.shields.io/badge/PEFT-LoRA-green" />
  <img src="https://img.shields.io/badge/vLLM-Serving-purple" />
  <img src="https://img.shields.io/badge/MLflow-Tracking-blue" />
</div>

---

## Overview

This project implements an end-to-end ML pipeline for fine-tuning open-source LLMs (Llama, Mistral) using parameter-efficient fine-tuning (PEFT) techniques. The pipeline includes:

- **Efficient Training**: QLoRA (4-bit quantization) for training on consumer GPUs
- **Experiment Tracking**: MLflow and Weights & Biases integration
- **Comprehensive Evaluation**: Task-specific metrics and benchmarking
- **Production Serving**: vLLM-powered high-performance inference API
- **Cost Analysis**: Detailed ROI calculations vs. commercial APIs

### Key Features

- **Parameter-Efficient Fine-tuning** with LoRA/QLoRA
- **4-bit Quantization** using bitsandbytes for memory efficiency
- **Automated Experiment Tracking** with MLflow
- **Custom Evaluation Metrics** for task-specific performance
- **Fast Inference Serving** with vLLM (50+ tokens/sec)
- **Docker Support** for reproducible training and deployment
- **Cloud Deployment Ready** (AWS, GCP compatible)

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Pipeline  â”‚â”€â”€â”€â”€â–¶â”‚  LoRA Training   â”‚â”€â”€â”€â”€â–¶â”‚   Evaluation    â”‚â”€â”€â”€â”€â–¶â”‚   Deployment    â”‚
â”‚  HuggingFace   â”‚     â”‚  QLoRA/PEFT      â”‚     â”‚  Custom Metrics â”‚     â”‚   vLLM Server   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                       â”‚                         â”‚                       â”‚
        â”‚                       â”‚                         â”‚                       â”‚
        â–¼                       â–¼                         â–¼                       â–¼
   Validation            MLflow/W&B              Benchmarking              FastAPI/REST
   Augmentation          Experiment              Comparison                Load Balancing
                         Tracking                Cost Analysis
```

---

## Quick Start

### Prerequisites

- Python 3.10+
- CUDA-capable GPU (8GB+ VRAM for training, 16GB+ recommended)
- HuggingFace account (for model access)

### Installation

```bash
# Clone the repository
git clone https://github.com/ashwani65/llm-finetuner.git
cd llm-finetuner

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
cp .env.example .env
# Edit .env with your API keys and configuration
```

### Training a Model

```bash
# Prepare your dataset
python scripts/prepare_data.py \
    --input data/raw/dataset.json \
    --output data/processed/

# Start training
python scripts/train.py \
    --config configs/llama_sql_config.yaml \
    --data data/processed/train.json \
    --output models/llama-sql-v1

# Monitor training
mlflow ui  # Visit http://localhost:5000
```

### Evaluation

```bash
python scripts/evaluate.py \
    --model models/llama-sql-v1 \
    --test_data data/processed/test.json \
    --output evaluation_results.json
```

### Deployment

```bash
# Start vLLM inference server
python -m src.serving.vllm_server \
    --model models/llama-sql-v1 \
    --port 8000

# Test the API
curl -X POST http://localhost:8000/generate \
    -H "Content-Type: application/json" \
    -d '{
        "prompt": "Generate SQL: Find all users who signed up in 2024",
        "max_tokens": 128,
        "temperature": 0.1
    }'
```

### Web Interface

Start the complete stack with frontend and backend:

```bash
# Terminal 1: Start Production API
./start_api.sh
# API: http://localhost:8000
# Docs: http://localhost:8000/docs

# Terminal 2: Start Frontend
cd frontend
npm run dev
# UI: http://localhost:3000
```

**Web Interface Features:**
- ğŸ“Š Real-time training monitoring
- ğŸ“ Dataset upload and management
- âš™ï¸ Interactive training configuration
- ğŸ“ˆ Evaluation results visualization
- ğŸš€ Model deployment controls
- ğŸ’» GPU monitoring

---

## Project Structure

```
llm-finetuner/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/              # Data preprocessing & validation
â”‚   â”‚   â”œâ”€â”€ dataset_builder.py
â”‚   â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”‚   â””â”€â”€ validation.py
â”‚   â”œâ”€â”€ training/          # Training pipeline
â”‚   â”‚   â”œâ”€â”€ trainer.py
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â””â”€â”€ callbacks.py
â”‚   â”œâ”€â”€ evaluation/        # Metrics & benchmarking
â”‚   â”‚   â”œâ”€â”€ metrics.py
â”‚   â”‚   â”œâ”€â”€ benchmarks.py
â”‚   â”‚   â””â”€â”€ comparison.py
â”‚   â”œâ”€â”€ serving/           # Inference & API server
â”‚   â”‚   â”œâ”€â”€ vllm_server.py
â”‚   â”‚   â”œâ”€â”€ production_api.py  # Production FastAPI backend
â”‚   â”‚   â””â”€â”€ api.py
â”‚   â”œâ”€â”€ monitoring/        # Experiment tracking
â”‚   â”‚   â”œâ”€â”€ mlflow_tracking.py
â”‚   â”‚   â””â”€â”€ wandb_logging.py
â”‚   â””â”€â”€ utils/             # Utilities
â”‚       â”œâ”€â”€ gpu_utils.py
â”‚       â”œâ”€â”€ model_utils.py
â”‚       â”œâ”€â”€ cost_calculator.py
â”‚       â”œâ”€â”€ database.py        # SQLite ORM models
â”‚       â””â”€â”€ job_manager.py     # Async training jobs
â”œâ”€â”€ configs/               # Configuration files
â”‚   â”œâ”€â”€ base_config.yaml
â”‚   â”œâ”€â”€ llama_sql_config.yaml
â”‚   â””â”€â”€ mistral_config.yaml
â”œâ”€â”€ scripts/               # Executable scripts
â”‚   â”œâ”€â”€ prepare_data.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â””â”€â”€ deploy.py
â”œâ”€â”€ notebooks/             # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_training_experiments.ipynb
â”‚   â””â”€â”€ 03_evaluation_analysis.ipynb
â”œâ”€â”€ frontend/              # React web interface
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/    # UI components
â”‚   â”‚   â”œâ”€â”€ services/      # API integration
â”‚   â”‚   â””â”€â”€ App.jsx
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ tests/                 # Unit tests
â”œâ”€â”€ docker/                # Docker configurations
â”‚   â”œâ”€â”€ Dockerfile.training
â”‚   â”œâ”€â”€ Dockerfile.serving
â”‚   â””â”€â”€ docker-compose.yml
â”œâ”€â”€ start_api.sh           # API startup script
â””â”€â”€ requirements.txt
```

---

## Use Cases

This pipeline supports various fine-tuning tasks:

### 1. SQL Generation
Fine-tune models to generate SQL queries from natural language.

```python
Input: "Find total revenue by product category in 2024"
Output: "SELECT category, SUM(revenue) FROM sales WHERE year = 2024 GROUP BY category"
```

### 2. Code Review
Train models to provide code review comments and suggestions.

### 3. Domain Q&A
Create specialized chatbots for specific domains (legal, medical, financial).

---

## Training Configuration

### LoRA Parameters

```yaml
lora:
  r: 16                    # LoRA rank
  lora_alpha: 32          # LoRA scaling
  lora_dropout: 0.05
  target_modules:         # Attention modules to apply LoRA
    - "q_proj"
    - "v_proj"
    - "k_proj"
    - "o_proj"
```

### Quantization (QLoRA)

```yaml
quantization:
  load_in_4bit: true
  bnb_4bit_compute_dtype: "float16"
  bnb_4bit_quant_type: "nf4"
  bnb_4bit_use_double_quant: true
```

### Training Hyperparameters

```yaml
training:
  num_train_epochs: 3
  batch_size: 4
  gradient_accumulation_steps: 4
  learning_rate: 2.0e-4
  warmup_steps: 100
  weight_decay: 0.01
```

---

## Performance Benchmarks

### Training Efficiency

| Model | GPU | VRAM Usage | Training Time | Cost |
|-------|-----|------------|---------------|------|
| Llama 2 7B (QLoRA) | A100 40GB | ~12GB | 8 hours | $20 |
| Mistral 7B (QLoRA) | A100 40GB | ~11GB | 6 hours | $15 |
| Llama 2 7B (Full) | A100 80GB | ~45GB | 24 hours | $60 |

### Inference Speed

| Serving Method | Tokens/sec | Latency (p50) | Throughput |
|----------------|------------|---------------|------------|
| vLLM | 55 | 120ms | 100 req/sec |
| HF Transformers | 12 | 850ms | 20 req/sec |

### Task Performance (SQL Generation)

| Model | Exact Match | BLEU | Cost/1K Queries |
|-------|-------------|------|-----------------|
| **Fine-tuned Llama 2 7B** | **0.73** | **0.68** | **$0.05** |
| GPT-4 Turbo | 0.89 | 0.82 | $10.00 |
| GPT-3.5 Turbo | 0.65 | 0.61 | $0.50 |

---

## Cost Analysis

### Training Costs

- **GPU**: A100 40GB @ $2.50/hour Ã— 8 hours = **$20**
- **Storage**: S3/GCS = **$2/month**
- **Total Training**: **~$22**

### Inference Costs (10K queries/month)

- **Self-hosted** (vLLM on T4): $0.35/hour Ã— 24 Ã— 30 = **$252/month**
- **GPT-4 API**: $10/1M tokens Ã— 5M tokens = **$50,000/month**
- **Savings**: **99.5%**

**Break-even point**: ~280 queries

---

## Experiment Tracking

### MLflow Integration

```python
# Automatic tracking in training
mlflow.log_params({
    "model_name": "llama-2-7b",
    "lora_r": 16,
    "learning_rate": 2e-4
})
mlflow.log_metrics({
    "train_loss": 0.234,
    "eval_loss": 0.198
})
```

### Weights & Biases

```python
# Enable W&B in config
tracking:
  use_wandb: true
  wandb_project: "llm-finetuner"
```

---

## Docker Deployment

### Build Training Container

```bash
docker build -f docker/Dockerfile.training -t llm-finetuner-train .

docker run --gpus all \
    -v $(pwd)/data:/app/data \
    -v $(pwd)/models:/app/models \
    llm-finetuner-train \
    python scripts/train.py --config configs/llama_sql_config.yaml
```

### Build Serving Container

```bash
docker build -f docker/Dockerfile.serving -t llm-finetuner-serve .

docker run --gpus all -p 8000:8000 \
    -v $(pwd)/models:/app/models \
    llm-finetuner-serve
```

### Docker Compose

```bash
docker-compose up -d
```

---

## Advanced Features

### Custom Evaluation Metrics

```python
from src.evaluation.metrics import SQLEvaluator

evaluator = SQLEvaluator()
results = evaluator.evaluate(predictions, references)
# Returns: exact_match, component_match, BLEU, ROUGE
```

### Model Comparison

```python
from src.evaluation.comparison import ModelComparison

comparison = ModelComparison(evaluator)
comparison.add_model("fine-tuned", predictions1, references)
comparison.add_model("gpt-4", predictions2, references)
comparison.plot_comparison(save_path="comparison.png")
```

### Cost Calculator

```python
from src.utils.cost_calculator import CostCalculator

calculator = CostCalculator()
results = calculator.compare_total_cost(
    training_cost=20,
    inference_queries=10000,
    gpu_type="A100-40GB"
)
print(f"Self-hosted: ${results['self_hosted']['total']:.2f}")
print(f"API cost: ${results['api']['total']:.2f}")
print(f"Savings: ${results['savings']:.2f}")
```

---

## Roadmap

- [ ] Support for Llama 3.2 and Mistral 0.3
- [ ] Multi-GPU distributed training
- [ ] Automatic hyperparameter tuning
- [ ] Integration with LangChain/LlamaIndex
- [ ] Support for RLHF (Reinforcement Learning from Human Feedback)
- [ ] Kubernetes deployment templates
- [ ] Prompt engineering utilities
- [ ] Dataset versioning with DVC

---

## Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## Tech Stack

**Core ML**: PyTorch, Transformers, PEFT, bitsandbytes, Accelerate, TRL

**Serving**: vLLM, FastAPI, Uvicorn

**Experiment Tracking**: MLflow, Weights & Biases

**Data**: Datasets, Pandas, NumPy, scikit-learn

**Evaluation**: BLEU, ROUGE, Custom Metrics

**Deployment**: Docker, Kubernetes (optional)

---

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## Citation

If you use this project in your research or production, please cite:

```bibtex
@misc{llm-finetuner,
  author = {Ashwani Singh},
  title = {LLM Fine-tuner: Production-Ready LoRA Fine-tuning Pipeline},
  year = {2024},
  publisher = {GitHub},
  url = {https://github.com/ashwani65/llm-finetuner}
}
```

---

## Acknowledgments

- HuggingFace for the Transformers and PEFT libraries
- vLLM team for the high-performance inference engine
- Meta AI for Llama 2
- Mistral AI for Mistral 7B

---

## Contact

**Ashwani Singh**
- GitHub: [@ashwani65](https://github.com/ashwani65)
- LinkedIn: [Ashwani Singh](https://www.linkedin.com/in/ashwani-singh-5b1868165/)
- Email: ashwani.11803318@gmail.com

---

<div align="center">
  <strong>Built with â¤ï¸ for the ML community</strong>
</div>
